{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3dfd3c5-be57-4565-8a04-f65b83311869",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load AWS access key, secret key and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1914d944-1d7f-4341-a9fc-882c332edbdd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d22ece06-6b6e-4e8d-b2b0-7e08c23812b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ACCESS_KEY = dbutils.secrets.get(scope=\"aws\", key=\"access_key_id\")\n",
    "SECRET_KEY = dbutils.secrets.get(scope=\"aws\", key=\"secret_access_key\")\n",
    "REGION = dbutils.secrets.get(scope=\"aws\", key=\"region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddc24eac-ecad-46ad-a03b-dd34cd55fb5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Stream transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71c3275e-6f52-4d04-89fc-dc540c6f0145",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the output and checkpoint paths for the cleaned user data\n",
    "outputPath = '/mnt/pinterest_data/test_streaming_delta_tables/0e3bbd435bfb_user_table'\n",
    "checkpointPath = '/mnt/pinterest_data/test_streaming_delta_tables/checkpoints/user'\n",
    "\n",
    "# define partition key\n",
    "partition_key = \"test_user\"\n",
    "\n",
    "# define aws access variables and a dataframe to read from kinesis stream\n",
    "awsAccessKeyId = ACCESS_KEY\n",
    "awsSecretKey = SECRET_KEY\n",
    "kinesisStreamName = \"streaming-0e3bbd435bfb-user\"\n",
    "kinesisRegion = REGION\n",
    "df = (spark.readStream\n",
    "    .format(\"kinesis\") \n",
    "    .option(\"streamName\", kinesisStreamName)\n",
    "    .option(\"region\", kinesisRegion)\n",
    "    .option(\"initialPosition\", \"LATEST\")\n",
    "    .option(\"format\", \"json\")\n",
    "    .option(\"awsAccessKey\", awsAccessKeyId)\n",
    "    .option(\"awsSecretKey\", awsSecretKey)\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"minFetchPeriod\", \"200ms\")\n",
    "    .load())\n",
    "\n",
    "# schema for the data\n",
    "schema = StructType([\n",
    "    StructField(\"ind\", LongType()),\n",
    "    StructField(\"first_name\", StringType()),\n",
    "    StructField(\"last_name\", StringType()),\n",
    "    StructField(\"age\", LongType()),\n",
    "    StructField(\"date_joined\", StringType())\n",
    "])\n",
    "\n",
    "# transformations\n",
    "transformed_df = (\n",
    "    # filter data with required shardId\n",
    "    df.filter(F.col(\"partitionKey\") == partition_key)\n",
    "\n",
    "        # decode the data column\n",
    "        .withColumn(\n",
    "            \"decoded_data\",\n",
    "            F.unbase64(\n",
    "                F.col(\"data\")\n",
    "            ).cast(\"string\")\n",
    "        )\n",
    "\n",
    "        # Use from_json to parse the JSON string in decoded_data and apply the schema\n",
    "        .withColumn(\"parsed_data\", F.from_json(F.col(\"decoded_data\"), schema))\n",
    "        \n",
    "        # select the individual fields from the parsed_data column\n",
    "        .select(\n",
    "            F.col(\"parsed_data.ind\"),\n",
    "            F.col(\"parsed_data.first_name\"),\n",
    "            F.col(\"parsed_data.last_name\"),\n",
    "            F.col(\"parsed_data.age\"),\n",
    "            F.col(\"parsed_data.date_joined\"),\n",
    "        )\n",
    "\n",
    "        # create a new column 'user_name' by concatenating 'first_name' and 'last_name'\n",
    "        .withColumn(\"user_name\", F.concat(F.col(\"first_name\"), F.col(\"last_name\")))\n",
    "\n",
    "        # drop first_name and last_name\n",
    "        .drop(\"first_name\", \"last_name\")\n",
    "\n",
    "        # convert the date_joined column from a string to a timestamp data type\n",
    "        .withColumn(\"date_joined\", F.to_timestamp(F.col(\"date_joined\")).cast(\"timestamp\"))\n",
    ")\n",
    "\n",
    "# write the stream to a delta table\n",
    "query = (\n",
    "    transformed_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", checkpointPath)\n",
    "    .start(outputPath)\n",
    ")\n",
    "\n",
    "# keep the stream running\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d413baeb-cc66-4bb3-a2c4-55a564935cb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "kinesis_user_data_stream_processing.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
